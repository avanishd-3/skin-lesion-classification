#  EfficientNet v2-M vs Dino v3-Base for Skin Lesion Classification

This project compares EfficientNet v2-M and DINO v3-Base on classifying skin lesions as benign or malignant.

## Project Structure

### Root Directory

- **`README.md`**: Overview of the project directory structure and running instructions
- **`skin_lesion_classification.ipynb`**: The Jupyter notebook used for training, evaluating, and saving the EfficientNet and DINO models.
- **`skin_lesion_classification_local.ipynb`**: Version of trainig notebook for local runtime.
- **`demo.ipynb`**: Download the trained DINO model and run inference on the PH2 dataset.
- **`.gitignore`**: Files for Git to ignore
- **`.python-version:`** Tells uv which version of Python to use when setting up venv
- **`pyproject.toml`**: Description of project and its dependencies
  - Similar to Cargo.toml
- **`uv.lock`**: Hash file for project dependencies (do not edit, this is generated by uv)
  - Similar to pnpm-lock.yaml and Cargo.lock

### Directories
- **`ph2_data`**: Files for PH2 dataset

## Demo Usage Instructions

### Recommended Runtime (Colab)

1. Upload `demo.ipynb` to Colab
2. Zip the ph2_data folder and upload `ph2_data.zip`to your Colab active session
3. Connect to a T4 Runtime (available under Runtime>change runtime type) on Colab.

### Running Locally (not tested and not recommended)

1. Install uv
2. Run uv sync
3. Zip `ph2_data` into `ph2_data.zip` 
3. Run `demo.ipynb`

Note: This assumes CUDA on Windows and Linux, and CPU on MacOS. If this is not the case for you, see [uv Pytorch guide](https://docs.astral.sh/uv/guides/integration/pytorch/) for updating pyproject.toml to use the correct builds for torch and torchvision.


## Training Usage Instructions

## Getting Data

The data is from the following publicly available datasets: 
- https://www.kaggle.com/competitions/isic-2024-challenge
- https://www.kaggle.com/datasets/ilya9711nov/isic-2024-synthetic/data

The data is also available at [this Google Drive link](https://drive.google.com/drive/folders/1xBomJrOHf-5Ae0OxfhhIOa6w7cF4imC9?usp=sharing), which is organized for this project. To use this, download the `skin_lesion_classification` folder and upload it to your Google Drive (it should be in MyDrive).

If not using the Google Drive link, you must have the following zip files. The directory structure shown for `isic-2024-synthetic.zip` is for the unzipped file. To achieve this, delete the lr subfolders from the original dataset and flatten all the hr folders into a single images folders before zipping up your isic-2024-synthetic folder.

```text
/
├── skin_lesion_classification
│   ├── isic-2024-challenge.zip
│   ├── isic-2024-synthetic.zip
│   │   └── images
│   │       └── IMG_NAME.png
```

### Recommended Runtime (Colab)

1. Upload `skin_lesion_classification.ipynb` to Colab
2. Upload the `skin_lesion_classification` folder to your Google Drive if you haven't already.
3. Connect to a T4 Runtime (available under Runtime>change runtime type) on Colab.

### Running Locally (not tested and not recommended)

1. Install uv
2. Run uv sync
3. Put `isic-2024-challenge.zip` and `isic-2024-synthetic.zip` into **`./content/data`**
3. Run `skin_lesion_classification_local.ipynb`

Note: This assumes CUDA on Windows and Linux, and CPU on MacOS. If this is not the case for you, see [uv Pytorch guide](https://docs.astral.sh/uv/guides/integration/pytorch/) for updating pyproject.toml to use the correct builds for torch and torchvision.

## Installing UV

See [installation guide](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer) for all options.

### Unix/MacOS

```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

or

```
brew install uv
```
### Windows

```
winget install --id=astral-sh.uv  -e
```